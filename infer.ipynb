{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":30892,"databundleVersionId":2715462,"sourceType":"competition"},{"sourceId":6974347,"sourceType":"datasetVersion","datasetId":4007448}],"dockerImageVersionId":30580,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport cv2\nsegmentation_transform = A.Compose([\n    # Randomly crops the image and resizes it back to the original size\n    A.RandomResizedCrop(height=512, width=512, scale=(0.8, 1.0), p=0.5),\n\n    # Random horizontal flipping\n    A.HorizontalFlip(p=0.5),\n\n    # Random vertical flipping\n    A.VerticalFlip(p=0.5),\n\n    # Randomly changes the brightness, contrast, and saturation of an image\n    A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.02, p=0.5),\n\n    # Randomly rotates the image\n    A.Rotate(limit=30, p=0.5, border_mode=cv2.BORDER_CONSTANT),\n\n    # Applies elastic transformations\n    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),\n\n    # Normalizes the image\n    A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n\n    # Converts the image to a PyTorch tensor\n    ToTensorV2(),\n])","metadata":{"execution":{"iopub.status.busy":"2023-11-15T14:09:11.668178Z","iopub.execute_input":"2023-11-15T14:09:11.668542Z","iopub.status.idle":"2023-11-15T14:09:11.676198Z","shell.execute_reply.started":"2023-11-15T14:09:11.668514Z","shell.execute_reply":"2023-11-15T14:09:11.674977Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!pip install segmentation-models-pytorch","metadata":{"execution":{"iopub.status.busy":"2023-11-15T14:09:47.423269Z","iopub.execute_input":"2023-11-15T14:09:47.423626Z","iopub.status.idle":"2023-11-15T14:10:09.327931Z","shell.execute_reply.started":"2023-11-15T14:09:47.423596Z","shell.execute_reply":"2023-11-15T14:10:09.326826Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Collecting segmentation-models-pytorch\n  Obtaining dependency information for segmentation-models-pytorch from https://files.pythonhosted.org/packages/cb/70/4aac1b240b399b108ce58029ae54bc14497e1bbc275dfab8fd3c84c1e35d/segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata\n  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl.metadata (30 kB)\nRequirement already satisfied: torchvision>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (0.15.1)\nCollecting pretrainedmodels==0.7.4 (from segmentation-models-pytorch)\n  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting efficientnet-pytorch==0.7.1 (from segmentation-models-pytorch)\n  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hCollecting timm==0.9.2 (from segmentation-models-pytorch)\n  Obtaining dependency information for timm==0.9.2 from https://files.pythonhosted.org/packages/29/90/94f5deb8d76e24a89813aef95e8809ca8fd7414490428480eda19b133d4a/timm-0.9.2-py3-none-any.whl.metadata\n  Downloading timm-0.9.2-py3-none-any.whl.metadata (68 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.5/68.5 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (4.66.1)\nRequirement already satisfied: pillow in /opt/conda/lib/python3.10/site-packages (from segmentation-models-pytorch) (10.1.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.0.0)\nCollecting munch (from pretrainedmodels==0.7.4->segmentation-models-pytorch)\n  Obtaining dependency information for munch from https://files.pythonhosted.org/packages/56/b3/7c69b37f03260a061883bec0e7b05be7117c1b1c85f5212c72c8c2bc3c8c/munch-4.0.0-py2.py3-none-any.whl.metadata\n  Downloading munch-4.0.0-py2.py3-none-any.whl.metadata (5.9 kB)\nRequirement already satisfied: pyyaml in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (6.0.1)\nRequirement already satisfied: huggingface-hub in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.17.3)\nRequirement already satisfied: safetensors in /opt/conda/lib/python3.10/site-packages (from timm==0.9.2->segmentation-models-pytorch) (0.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (1.24.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from torchvision>=0.5.0->segmentation-models-pytorch) (2.31.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.12.2)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (4.5.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (2023.10.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (21.3)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.2.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->torchvision>=0.5.0->segmentation-models-pytorch) (2023.7.22)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface-hub->timm==0.9.2->segmentation-models-pytorch) (3.0.9)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->efficientnet-pytorch==0.7.1->segmentation-models-pytorch) (1.3.0)\nDownloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\nBuilding wheels for collected packages: efficientnet-pytorch, pretrainedmodels\n  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=66acbbefb2d5dd045b1f8367eb63dbc9cdb650deffa1a31aca7142eb42d06a9a\n  Stored in directory: /root/.cache/pip/wheels/03/3f/e9/911b1bc46869644912bda90a56bcf7b960f20b5187feea3baf\n  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=705918153df9de4d7ac1941ea7d6ce509ba96bac27542483cd5d102359149c07\n  Stored in directory: /root/.cache/pip/wheels/35/cb/a5/8f534c60142835bfc889f9a482e4a67e0b817032d9c6883b64\nSuccessfully built efficientnet-pytorch pretrainedmodels\nInstalling collected packages: munch, efficientnet-pytorch, timm, pretrainedmodels, segmentation-models-pytorch\n  Attempting uninstall: timm\n    Found existing installation: timm 0.9.10\n    Uninstalling timm-0.9.10:\n      Successfully uninstalled timm-0.9.10\nSuccessfully installed efficientnet-pytorch-0.7.1 munch-4.0.0 pretrainedmodels-0.7.4 segmentation-models-pytorch-0.3.3 timm-0.9.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport cv2\nimport os\nimport segmentation_models_pytorch as smp\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim","metadata":{"execution":{"iopub.status.busy":"2023-11-15T14:13:05.260726Z","iopub.execute_input":"2023-11-15T14:13:05.261090Z","iopub.status.idle":"2023-11-15T14:13:05.266254Z","shell.execute_reply.started":"2023-11-15T14:13:05.261063Z","shell.execute_reply":"2023-11-15T14:13:05.265263Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"***Change the path of best_model.pth***","metadata":{}},{"cell_type":"code","source":"checkpoint = torch.load('/kaggle/input/model-file/best_model.pth')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T14:14:13.340551Z","iopub.execute_input":"2023-11-15T14:14:13.341412Z","iopub.status.idle":"2023-11-15T14:14:20.862367Z","shell.execute_reply.started":"2023-11-15T14:14:13.341376Z","shell.execute_reply":"2023-11-15T14:14:20.861399Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"import os\nos.mkdir('/kaggle/working/predicted_mask')","metadata":{"execution":{"iopub.status.busy":"2023-11-15T14:18:05.623977Z","iopub.execute_input":"2023-11-15T14:18:05.624833Z","iopub.status.idle":"2023-11-15T14:18:05.629081Z","shell.execute_reply.started":"2023-11-15T14:18:05.624799Z","shell.execute_reply":"2023-11-15T14:18:05.628117Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")\nmodel = smp.Unet(\n    encoder_name=\"resnet34\",        \n    encoder_weights=\"imagenet\",     \n    in_channels=3,                  \n    classes=3     \n)\noptimizer = optim.Adam(model.parameters(), lr=0.0001)\n\nmodel.load_state_dict(checkpoint['model'])\noptimizer.load_state_dict(checkpoint['optimizer'])\nepoch = checkpoint['epoch']\nloss = checkpoint['loss']\n\nmodel = model.to(device)\nmodel.eval()\nfor i in os.listdir(\"/kaggle/input/bkai-igh-neopolyp/test/test\"):\n    img_path = os.path.join(\"/kaggle/input/bkai-igh-neopolyp/test/test\", i)\n    ori_img = cv2.imread(img_path)\n    ori_img = cv2.cvtColor(ori_img, cv2.COLOR_BGR2RGB)\n    ori_w = ori_img.shape[0]\n    ori_h = ori_img.shape[1]\n    img = cv2.resize(ori_img, (512, 512))\n    transformed = segmentation_transform(image=img)\n    input_img = transformed[\"image\"]\n    input_img = input_img.unsqueeze(0).to(device)\n    with torch.no_grad():\n        output_mask = model.forward(input_img).squeeze(0).cpu().numpy().transpose(1,2,0)\n    mask = cv2.resize(output_mask, (ori_h, ori_w))\n    mask = np.argmax(mask, axis=2)\n#     new_rgb_mask = np.zeros((*mask.shape, 3)).astype(np.uint8)\n#     mask_rgb = mask_to_rgb(mask, color_dict)\n#     cv2.imwrite(\"/kaggle/working/predicted_mask/{}\".format(i), mask_rgb)\n    cv2.imwrite(\"/kaggle/working/predicted_mask/{}\".format(i), mask)\n\ndef rle_to_string(runs):\n    return ' '.join(str(x) for x in runs)\n\ndef rle_encode_one_mask(mask):\n    pixels = mask.flatten()\n    pixels[pixels > 225] = 255\n    pixels[pixels <= 225] = 0\n    use_padding = False\n    if pixels[0] or pixels[-1]:\n        use_padding = True\n        pixel_padded = np.zeros([len(pixels) + 2], dtype=pixels.dtype)\n        pixel_padded[1:-1] = pixels\n        pixels = pixel_padded\n    \n    rle = np.where(pixels[1:] != pixels[:-1])[0] + 2\n    if use_padding:\n        rle = rle - 1\n    rle[1::2] = rle[1::2] - rle[:-1:2]\n    return rle_to_string(rle)\n\ndef rle2mask(mask_rle, shape=(3,3)):\n    '''\n    mask_rle: run-length as string formated (start length)\n    shape: (width,height) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape).T\n\ndef mask2string(dir):\n    ## mask --> string\n    strings = []\n    ids = []\n    ws, hs = [[] for i in range(2)]\n    for image_id in os.listdir(dir):\n        id = image_id.split('.')[0]\n        path = os.path.join(dir, image_id)\n        print(path)\n        img = cv2.imread(path)[:,:,::-1]\n        h, w = img.shape[0], img.shape[1]\n        for channel in range(2):\n            ws.append(w)\n            hs.append(h)\n            ids.append(f'{id}_{channel}')\n            string = rle_encode_one_mask(img[:,:,channel])\n            strings.append(string)\n    r = {\n        'ids': ids,\n        'strings': strings,\n    }\n    return r\n\n\nMASK_DIR_PATH = '/kaggle/working/predicted_mask' # change this to the path to your output mask folder\ndir = MASK_DIR_PATH\nres = mask2string(dir)\ndf = pd.DataFrame(columns=['Id', 'Expected'])\ndf['Id'] = res['ids']\ndf['Expected'] = res['strings']\n\ndf.to_csv(r'output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-11-15T14:18:10.898381Z","iopub.execute_input":"2023-11-15T14:18:10.899283Z","iopub.status.idle":"2023-11-15T14:18:55.965109Z","shell.execute_reply.started":"2023-11-15T14:18:10.899246Z","shell.execute_reply":"2023-11-15T14:18:55.964180Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"/kaggle/working/predicted_mask/3bbc04a3afe1f119f21b248d152b672a.jpeg\n/kaggle/working/predicted_mask/7cdf3f33c3ca4d5060a633a8d5b2b2b5.jpeg\n/kaggle/working/predicted_mask/1002ec4a1fe748f3085f1ce88cbdf366.jpeg\n/kaggle/working/predicted_mask/e73749a0d21db70dd094a7f32574d6c7.jpeg\n/kaggle/working/predicted_mask/5e8f14e1e0ae936de314f2d95e6c487f.jpeg\n/kaggle/working/predicted_mask/2a365b5574868eb60861ee1ff0b8a4f6.jpeg\n/kaggle/working/predicted_mask/1b62f15ec83b97bb11e8e0c4416c1931.jpeg\n/kaggle/working/predicted_mask/a6d9ba9d45c3dbc695325ded465efde9.jpeg\n/kaggle/working/predicted_mask/a9d45c3dbc695325ded465efde988dfb.jpeg\n/kaggle/working/predicted_mask/559c7e610b1531871f2fd85a04faeeb2.jpeg\n/kaggle/working/predicted_mask/71f2fd85a04faeeb2b535797395305af.jpeg\n/kaggle/working/predicted_mask/39dda50f954ba59c7de13a35276a4764.jpeg\n/kaggle/working/predicted_mask/a15fc656702fa602bb3c7abacdbd7e6a.jpeg\n/kaggle/working/predicted_mask/50534bca540e24f489284b8e6953ad88.jpeg\n/kaggle/working/predicted_mask/5c1346e62522325c1b9c4fc9cbe1eca1.jpeg\n/kaggle/working/predicted_mask/cf464aa36bf7c09a3bb0e5ca159410b9.jpeg\n/kaggle/working/predicted_mask/13dd311a65d2b46d0a6085835c525af6.jpeg\n/kaggle/working/predicted_mask/82ea2c193ac8d551c149b60f2965341c.jpeg\n/kaggle/working/predicted_mask/314fe384eb2ba3adfda6c1899fdc9837.jpeg\n/kaggle/working/predicted_mask/d077bad31c8c5f54ffaa27a623511c38.jpeg\n/kaggle/working/predicted_mask/7936140a2d5fc1443c4e445927738677.jpeg\n/kaggle/working/predicted_mask/d5060a633a8d5b2b2b55157b7781e2c7.jpeg\n/kaggle/working/predicted_mask/fdbc3bbc04a3afe1f119f21b248d152b.jpeg\n/kaggle/working/predicted_mask/02fa602bb3c7abacdbd7e6afd56ea7bc.jpeg\n/kaggle/working/predicted_mask/0fca6a4248a41e8db8b4ed633b456aaa.jpeg\n/kaggle/working/predicted_mask/0af3feff05dec1eb3a70b145a7d8d3b6.jpeg\n/kaggle/working/predicted_mask/3dd311a65d2b46d0a6085835c525af63.jpeg\n/kaggle/working/predicted_mask/425b976973f13dd311a65d2b46d0a608.jpeg\n/kaggle/working/predicted_mask/6231002ec4a1fe748f3085f1ce88cbdf.jpeg\n/kaggle/working/predicted_mask/cbb2a365b5574868eb60861ee1ff0b8a.jpeg\n/kaggle/working/predicted_mask/ea42b4eebc9e5a87e443434ac60af150.jpeg\n/kaggle/working/predicted_mask/df8e26031fbb5e52c41545ba55aadaa7.jpeg\n/kaggle/working/predicted_mask/db5eb2a0e4b50889d874c68c030b9afe.jpeg\n/kaggle/working/predicted_mask/fb905b78a91391adc0bb223c4eaf3372.jpeg\n/kaggle/working/predicted_mask/677a6b1f2c6d40b3bbba8f6c704801b3.jpeg\n/kaggle/working/predicted_mask/98da48d679d7c7c8d3d96fb2b87fbbcf.jpeg\n/kaggle/working/predicted_mask/dc0bb223c4eaf3372eae567c94ea04c6.jpeg\n/kaggle/working/predicted_mask/0a5f3601ad4f13ccf1f4b331a412fc44.jpeg\n/kaggle/working/predicted_mask/e3c84417fda8019410b1fcf0625f608b.jpeg\n/kaggle/working/predicted_mask/8954bb13d3727c7e5e1069646f2f0bb8.jpeg\n/kaggle/working/predicted_mask/72d9e593b6be1ac29adbe86f03d900fd.jpeg\n/kaggle/working/predicted_mask/67d4dcf9596154efb7cef748d9cbd617.jpeg\n/kaggle/working/predicted_mask/80cae6daedd989517cb8041ed86e5822.jpeg\n/kaggle/working/predicted_mask/f7fdb2d45b21960c94b0aab4c024a573.jpeg\n/kaggle/working/predicted_mask/c4be73749a0d21db70dd094a7f32574d.jpeg\n/kaggle/working/predicted_mask/395e56a6d9ba9d45c3dbc695325ded46.jpeg\n/kaggle/working/predicted_mask/4c1711b62f15ec83b97bb11e8e0c4416.jpeg\n/kaggle/working/predicted_mask/019410b1fcf0625f608b4ce97629ab55.jpeg\n/kaggle/working/predicted_mask/a6a4248a41e8db8b4ed633b456aaafac.jpeg\n/kaggle/working/predicted_mask/8eb5a9a8a8d7fcc9df8e5ad89d284483.jpeg\n/kaggle/working/predicted_mask/a51625559c7e610b1531871f2fd85a04.jpeg\n/kaggle/working/predicted_mask/5664c1711b62f15ec83b97bb11e8e0c4.jpeg\n/kaggle/working/predicted_mask/7b5df7cdf3f33c3ca4d5060a633a8d5b.jpeg\n/kaggle/working/predicted_mask/fcd6da15fc656702fa602bb3c7abacdb.jpeg\n/kaggle/working/predicted_mask/343f27ebc5d92b9076135d76d0bbd4ce.jpeg\n/kaggle/working/predicted_mask/6d3694abb47953b0e4909384b57bb6a0.jpeg\n/kaggle/working/predicted_mask/41ed86e58224cb76a67d4dcf9596154e.jpeg\n/kaggle/working/predicted_mask/30c2f4fc276ed9f178dc2f4af6266509.jpeg\n/kaggle/working/predicted_mask/1c0e9082ea2c193ac8d551c149b60f29.jpeg\n/kaggle/working/predicted_mask/97e1c0e9082ea2c193ac8d551c149b60.jpeg\n/kaggle/working/predicted_mask/e56a6d9ba9d45c3dbc695325ded465ef.jpeg\n/kaggle/working/predicted_mask/aeeb2b535797395305af926a6f23c5d6.jpeg\n/kaggle/working/predicted_mask/6ddca6ee1af35b65bd9ea42cfcfedb5e.jpeg\n/kaggle/working/predicted_mask/bec33b5e3d68f9d4c331587f9b9d49e2.jpeg\n/kaggle/working/predicted_mask/318ecf467d7ad048df39beb176363408.jpeg\n/kaggle/working/predicted_mask/7fda8019410b1fcf0625f608b4ce9762.jpeg\n/kaggle/working/predicted_mask/f14e1e0ae936de314f2d95e6c487ffa6.jpeg\n/kaggle/working/predicted_mask/faef7fdb2d45b21960c94b0aab4c024a.jpeg\n/kaggle/working/predicted_mask/c193ac8d551c149b60f2965341caf528.jpeg\n/kaggle/working/predicted_mask/eb1ef57af2ed9fbb63b28163a745959c.jpeg\n/kaggle/working/predicted_mask/a48847ae8395e56a6d9ba9d45c3dbc69.jpeg\n/kaggle/working/predicted_mask/3c84417fda8019410b1fcf0625f608b4.jpeg\n/kaggle/working/predicted_mask/cc5cfd263f1f90be28799235026b3550.jpeg\n/kaggle/working/predicted_mask/63b8318ecf467d7ad048df39beb17636.jpeg\n/kaggle/working/predicted_mask/6f4d4987ea3b4bae5672a230194c5a08.jpeg\n/kaggle/working/predicted_mask/8cbdf366e057db382b8564872a27301a.jpeg\n/kaggle/working/predicted_mask/285e26c90e1797c77826f9a7021bab9f.jpeg\n/kaggle/working/predicted_mask/710d568df17586ad8f3297c819c90895.jpeg\n/kaggle/working/predicted_mask/692195f853af7f8a4df1ec859759b7c8.jpeg\n/kaggle/working/predicted_mask/e19769fa2d37d32780fd497e1c0e9082.jpeg\n/kaggle/working/predicted_mask/9fc7330398846f67b5df7cdf3f33c3ca.jpeg\n/kaggle/working/predicted_mask/9632a3c6f7f7fb2a643f15bd0249ddcc.jpeg\n/kaggle/working/predicted_mask/1209db6dcdda5cc8a788edaeb6aa460a.jpeg\n/kaggle/working/predicted_mask/633a8d5b2b2b55157b7781e2c706c75c.jpeg\n/kaggle/working/predicted_mask/6b83ef461c2a337948a41964c1d4f50a.jpeg\n/kaggle/working/predicted_mask/4e2a6e51d077bad31c8c5f54ffaa27a6.jpeg\n/kaggle/working/predicted_mask/26679bff55177a34fc01019eec999fd8.jpeg\n/kaggle/working/predicted_mask/66e057db382b8564872a27301a654864.jpeg\n/kaggle/working/predicted_mask/39d6aad6bb0170a40ed32deef71fbe08.jpeg\n/kaggle/working/predicted_mask/f8e5ad89d2844837f2a0f1536ad3f6a5.jpeg\n/kaggle/working/predicted_mask/c7e610b1531871f2fd85a04faeeb2b53.jpeg\n/kaggle/working/predicted_mask/85a04faeeb2b535797395305af926a6f.jpeg\n/kaggle/working/predicted_mask/aafac813fe3ccba3e032dd2948a80c64.jpeg\n/kaggle/working/predicted_mask/88e16d4ca6160127cd1d5ff99c267599.jpeg\n/kaggle/working/predicted_mask/4fda8daadc8dd23ae214d84b5dec33fd.jpeg\n/kaggle/working/predicted_mask/268d4b4ef4d95ceea11957998906d369.jpeg\n/kaggle/working/predicted_mask/3c692195f853af7f8a4df1ec859759b7.jpeg\n/kaggle/working/predicted_mask/f8e26031fbb5e52c41545ba55aadaa77.jpeg\n/kaggle/working/predicted_mask/af35b65bd9ea42cfcfedb5eb2a0e4b50.jpeg\n/kaggle/working/predicted_mask/15fc656702fa602bb3c7abacdbd7e6af.jpeg\n/kaggle/working/predicted_mask/e5e8f14e1e0ae936de314f2d95e6c487.jpeg\n/kaggle/working/predicted_mask/cb1b387133b51209db6dcdda5cc8a788.jpeg\n/kaggle/working/predicted_mask/e2cd066b9fdbc3bbc04a3afe1f119f21.jpeg\n/kaggle/working/predicted_mask/dc70626ab4ec3d46e602b296cc5cfd26.jpeg\n/kaggle/working/predicted_mask/8fa8625605da2023387fd56c04414eaa.jpeg\n/kaggle/working/predicted_mask/df366e057db382b8564872a27301a654.jpeg\n/kaggle/working/predicted_mask/f13dd311a65d2b46d0a6085835c525af.jpeg\n/kaggle/working/predicted_mask/936de314f2d95e6c487ffa651b477422.jpeg\n/kaggle/working/predicted_mask/626650908b1cb932a767bf5487ced51b.jpeg\n/kaggle/working/predicted_mask/3657e4314fe384eb2ba3adfda6c1899f.jpeg\n/kaggle/working/predicted_mask/1db239dda50f954ba59c7de13a35276a.jpeg\n/kaggle/working/predicted_mask/4e8bfb905b78a91391adc0bb223c4eaf.jpeg\n/kaggle/working/predicted_mask/b21960c94b0aab4c024a573c692195f8.jpeg\n/kaggle/working/predicted_mask/27738677a6b1f2c6d40b3bbba8f6c704.jpeg\n/kaggle/working/predicted_mask/0398846f67b5df7cdf3f33c3ca4d5060.jpeg\n/kaggle/working/predicted_mask/b70dd094a7f32574d6c748c41743c6c0.jpeg\n/kaggle/working/predicted_mask/7cb2eb1ef57af2ed9fbb63b28163a745.jpeg\n/kaggle/working/predicted_mask/c656702fa602bb3c7abacdbd7e6afd56.jpeg\n/kaggle/working/predicted_mask/ff55177a34fc01019eec999fd84e679b.jpeg\n/kaggle/working/predicted_mask/9c7976c1182df0de51d32128c358d1fd.jpeg\n/kaggle/working/predicted_mask/be4d18d5401f659532897255ce2dd4ae.jpeg\n/kaggle/working/predicted_mask/1ad4f13ccf1f4b331a412fc44655fb51.jpeg\n/kaggle/working/predicted_mask/a3657e4314fe384eb2ba3adfda6c1899.jpeg\n/kaggle/working/predicted_mask/cf6644589e532a9ee954f81faedbce39.jpeg\n/kaggle/working/predicted_mask/05734fbeedd0f9da760db74a29abdb04.jpeg\n/kaggle/working/predicted_mask/c41545ba55aadaa77712a48e11d579d9.jpeg\n/kaggle/working/predicted_mask/54ba59c7de13a35276a476420655433a.jpeg\n/kaggle/working/predicted_mask/8395e56a6d9ba9d45c3dbc695325ded4.jpeg\n/kaggle/working/predicted_mask/d6bf62f215f0da4ad3a7ab8df9da7386.jpeg\n/kaggle/working/predicted_mask/dd094a7f32574d6c748c41743c6c08a1.jpeg\n/kaggle/working/predicted_mask/8b8ec74baddc22268d4b4ef4d95ceea1.jpeg\n/kaggle/working/predicted_mask/0619ebebe9e9c9d00a4262b4fe4a5a95.jpeg\n/kaggle/working/predicted_mask/6679bff55177a34fc01019eec999fd84.jpeg\n/kaggle/working/predicted_mask/1531871f2fd85a04faeeb2b535797395.jpeg\n/kaggle/working/predicted_mask/be86f03d900fd197cd955fa095f97845.jpeg\n/kaggle/working/predicted_mask/4417fda8019410b1fcf0625f608b4ce9.jpeg\n/kaggle/working/predicted_mask/3425b976973f13dd311a65d2b46d0a60.jpeg\n/kaggle/working/predicted_mask/3c3ca4d5060a633a8d5b2b2b55157b77.jpeg\n/kaggle/working/predicted_mask/5026b3550534bca540e24f489284b8e6.jpeg\n/kaggle/working/predicted_mask/d694539ef2424a9218697283baa3657e.jpeg\n/kaggle/working/predicted_mask/45b21960c94b0aab4c024a573c692195.jpeg\n/kaggle/working/predicted_mask/ff05dec1eb3a70b145a7d8d3b6c0ed75.jpeg\n/kaggle/working/predicted_mask/d6240619ebebe9e9c9d00a4262b4fe4a.jpeg\n/kaggle/working/predicted_mask/e1797c77826f9a7021bab9fc73303988.jpeg\n/kaggle/working/predicted_mask/fe1f119f21b248d152b672ab3492fc62.jpeg\n/kaggle/working/predicted_mask/94a7f32574d6c748c41743c6c08a1d1a.jpeg\n/kaggle/working/predicted_mask/2cd066b9fdbc3bbc04a3afe1f119f21b.jpeg\n/kaggle/working/predicted_mask/7330398846f67b5df7cdf3f33c3ca4d5.jpeg\n/kaggle/working/predicted_mask/c5a0808bee60b246359c68c836f843dc.jpeg\n/kaggle/working/predicted_mask/3f33c3ca4d5060a633a8d5b2b2b55157.jpeg\n/kaggle/working/predicted_mask/2ed9fbb63b28163a745959c03983064a.jpeg\n/kaggle/working/predicted_mask/780fd497e1c0e9082ea2c193ac8d551c.jpeg\n/kaggle/working/predicted_mask/7f0019f7e6af7d7147763bdfb928d788.jpeg\n/kaggle/working/predicted_mask/0626ab4ec3d46e602b296cc5cfd263f1.jpeg\n/kaggle/working/predicted_mask/eecd70ebce6347c491b37c8c2e5a64a8.jpeg\n/kaggle/working/predicted_mask/60a633a8d5b2b2b55157b7781e2c706c.jpeg\n/kaggle/working/predicted_mask/e4a17af18f72c8e6166a915669c99390.jpeg\n/kaggle/working/predicted_mask/ad43fe2cd066b9fdbc3bbc04a3afe1f1.jpeg\n/kaggle/working/predicted_mask/e1e0ae936de314f2d95e6c487ffa651b.jpeg\n/kaggle/working/predicted_mask/e9082ea2c193ac8d551c149b60f29653.jpeg\n/kaggle/working/predicted_mask/e8bfb905b78a91391adc0bb223c4eaf3.jpeg\n/kaggle/working/predicted_mask/60b246359c68c836f843dcf41f4dce3c.jpeg\n/kaggle/working/predicted_mask/c695325ded465efde988dfb96d081533.jpeg\n/kaggle/working/predicted_mask/80c643782707d7c359e27888daefee82.jpeg\n/kaggle/working/predicted_mask/eff05dec1eb3a70b145a7d8d3b6c0ed7.jpeg\n/kaggle/working/predicted_mask/7f32574d6c748c41743c6c08a1d1ad8f.jpeg\n/kaggle/working/predicted_mask/c22268d4b4ef4d95ceea11957998906d.jpeg\n/kaggle/working/predicted_mask/4f437f0019f7e6af7d7147763bdfb928.jpeg\n/kaggle/working/predicted_mask/e7998934d417cb2eb1ef57af2ed9fbb6.jpeg\n/kaggle/working/predicted_mask/7ad1cf2eb9d32a3dc907950289e976c7.jpeg\n/kaggle/working/predicted_mask/391adc0bb223c4eaf3372eae567c94ea.jpeg\n/kaggle/working/predicted_mask/4baddc22268d4b4ef4d95ceea1195799.jpeg\n/kaggle/working/predicted_mask/7af2ed9fbb63b28163a745959c039830.jpeg\n/kaggle/working/predicted_mask/ca4d5060a633a8d5b2b2b55157b7781e.jpeg\n/kaggle/working/predicted_mask/5beb48f0be11d0309d1dff09b8405734.jpeg\n/kaggle/working/predicted_mask/4ef4d95ceea11957998906d3694abb47.jpeg\n/kaggle/working/predicted_mask/0a0317371a966bf4b3466463a3c64db1.jpeg\n/kaggle/working/predicted_mask/a6e51d077bad31c8c5f54ffaa27a6235.jpeg\n/kaggle/working/predicted_mask/2d9e593b6be1ac29adbe86f03d900fd1.jpeg\n/kaggle/working/predicted_mask/dd78294679c9cbb2a365b5574868eb60.jpeg\n/kaggle/working/predicted_mask/782707d7c359e27888daefee82519763.jpeg\n/kaggle/working/predicted_mask/625559c7e610b1531871f2fd85a04fae.jpeg\n/kaggle/working/predicted_mask/afe1f119f21b248d152b672ab3492fc6.jpeg\n/kaggle/working/predicted_mask/5a51625559c7e610b1531871f2fd85a0.jpeg\n/kaggle/working/predicted_mask/68d4b4ef4d95ceea11957998906d3694.jpeg\n/kaggle/working/predicted_mask/05b78a91391adc0bb223c4eaf3372eae.jpeg\n/kaggle/working/predicted_mask/6f67b5df7cdf3f33c3ca4d5060a633a8.jpeg\n/kaggle/working/predicted_mask/77e004e8bfb905b78a91391adc0bb223.jpeg\n/kaggle/working/predicted_mask/6240619ebebe9e9c9d00a4262b4fe4a5.jpeg\n/kaggle/working/predicted_mask/cb2eb1ef57af2ed9fbb63b28163a7459.jpeg\n/kaggle/working/predicted_mask/998906d3694abb47953b0e4909384b57.jpeg\n/kaggle/working/predicted_mask/3b8318ecf467d7ad048df39beb176363.jpeg\n/kaggle/working/predicted_mask/6ad1468996b4a9ce6d840b53a6558038.jpeg\n/kaggle/working/predicted_mask/87133b51209db6dcdda5cc8a788edaeb.jpeg\n/kaggle/working/predicted_mask/cdf3f33c3ca4d5060a633a8d5b2b2b55.jpeg\n/kaggle/working/predicted_mask/5b21960c94b0aab4c024a573c692195f.jpeg\n/kaggle/working/predicted_mask/d3694abb47953b0e4909384b57bb6a05.jpeg\n/kaggle/working/predicted_mask/4ca6160127cd1d5ff99c267599fc487b.jpeg\n/kaggle/working/predicted_mask/461c2a337948a41964c1d4f50a5f3601.jpeg\n/kaggle/working/predicted_mask/f62f215f0da4ad3a7ab8df9da7386835.jpeg\n","output_type":"stream"}]}]}